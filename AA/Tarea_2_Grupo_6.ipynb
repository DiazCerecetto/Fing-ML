{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ewvt9NVLPdX"
      },
      "source": [
        "# Task 2 - Bayesian classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The objective of this work is to build a model that allows predicting the next word of a sentence given the last N words that have been written, using the Naive Bayes algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1kaavDELPdf"
      },
      "source": [
        "# 1. Objetivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_v20_DcLPdg"
      },
      "source": [
        "El objetivo de esta tarea es construir un modelo que permita predecir la siguiente palabra de una frase dadas las últimas N palabras que se han escrito, utilizando el algoritmo de Naive Bayes.\n",
        "\n",
        "El éxito del aprendizaje se mide a través de que tan preciso es el modelo a la hora de predecir correctamente la última palabra de un mensaje obtenido de un grupo de Whatsapp.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeBUzPUeTeh1"
      },
      "source": [
        "#### Imports necesarios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaZMvUINAUSU"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter, defaultdict\n",
        "import nltk\n",
        "import csv\n",
        "import codecs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vd91GqfNgGw"
      },
      "source": [
        "# 2. Carga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLjN6uR0ugJP"
      },
      "source": [
        "Importamos un conjunto de 636,598 palabras en español para que funcione como un diccionario y así luego poder cruzarlo con las palabras presentes en el chat.\n",
        "\n",
        "Una de las razones para utilizar dicho archivo es que el mismo abarca una cantidad razonablemente alta de palabras en español y estas poseen los tildes correspondientes, lo cual nos parece útil para sugerir palabras correctas sintácticamente. Esto último se debe a que, el diccionario sugerido en el EVA del curso, que poseía un cardinal similar, no contaba con palabras con tildes. Luego de obtener la lista de palabras, eliminamos el '\\n' que poseía cada una y las pasamos a un objeto diccionario de Python, para poder consultar de forma más eficiente si una palabra pertenece al conjunto exportado o no. Además, agregamos la palabra 'jajaja' al mismo, pues la misma no se encontraba en el archivo exportado y resulta ser una palabra muy frecuente en los grupos de WhatsApp, por lo que creemos que es conveniente agregarla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7jMQkCMJUe5",
        "outputId": "e55a1b3c-301a-4813-fded-aafde85faf76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'aba', 'ába', 'abaá', 'ababilla', 'ababílla', 'ababillaba', 'ababillabais', 'ababillábamos', 'ababillaban']\n",
            "Cantidad de palabras del diccionario:  646615\n"
          ]
        }
      ],
      "source": [
        "with open('0_palabras_todas.txt', 'r', encoding='utf-8') as f:\n",
        "    vocabulario_lista = [line.strip() for line in f]\n",
        "vocabulario_limpio = [re.sub(r'[^a-zA-ZáéíóúÁÉÍÓÚñÑüÜ]', '', word) for word in vocabulario_lista]\n",
        "vocabulario_sin_vacios = [word for word in vocabulario_limpio if word]\n",
        "print(vocabulario_sin_vacios[:10])\n",
        "print(\"Cantidad de palabras del diccionario: \",len(vocabulario_sin_vacios))\n",
        "diccionario = {item: item for item in vocabulario_sin_vacios}\n",
        "diccionario['jajaja'] = 'jajaja'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56NYDWm0UpGs"
      },
      "source": [
        "Cargamos los datos que utilizaremos, es decir, cargamos la exportación que nos otorga Whatsapp en un archivo formato .txt (el nombre del archivo debe ser \"_chat.txt\"):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzLIL-dopVMt",
        "outputId": "0d571593-2eec-40de-e3ea-0aa151ada501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text\n",
            "0  [1/3/21 10:45:30] IIS: ‎Los mensajes y las lla...\n",
            "1  [1/3/21 10:45:30] ‪+598 94 721 195‬: ‎‪+598 94...\n",
            "2  [26/2/23 14:24:10] IIS: ‎Te uniste mediante el...\n",
            "3  [26/2/23 14:52:53] ‪+598 99 298 477‬: ‎‪+598 9...\n",
            "4  [26/2/23 18:26:22] ~ Luispe: ‎~ Luispe se unió...\n"
          ]
        }
      ],
      "source": [
        "with open('_chat.txt', 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "df = pd.DataFrame(lines, columns=['text'])\n",
        "# Visualizamos el resultado\n",
        "print(df.head(5).apply(lambda x: x.str.encode('utf-8', 'ignore').str.decode('utf-8')))\n",
        "# Pasamos el contenido del Dataframe que hemos modificado a una lista\n",
        "chat_lista = df.values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsHimgk5LPdg"
      },
      "source": [
        "# 3. Diseño"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdMsc4twLPdh"
      },
      "source": [
        "En esta sección presentamos las decisiones tomadas a la hora de implementar el predictor de palabras.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCaqltVCNaLQ"
      },
      "source": [
        "## 3.1 Preprocesamiento de datos\n",
        "\n",
        "- Pasamos a minúsculas todo el texto para identificar correctamente las palabras de cada mensaje en nuestro diccionario\n",
        "- Se decide eliminar de los mensajes:\n",
        "\n",
        "> * URLs.\n",
        "> * Saltos de línea (\"\\n\").\n",
        "> * Indicaciones de archivos omitidos a la hora de exportar el chat\n",
        "> * Signos de puntuación, excepto los tildes.\n",
        "> * Notificaciones de Whatsapp. Tales como mensajes eliminados, ingresos y abandonos del chat, notificaciones de cifrado, etc.\n",
        "\n",
        "\n",
        "- Se sustituyen:\n",
        "\n",
        "\n",
        "> * Expresiones referentes a risas por la expresión \"jajaja\" para homogeneizar las mismas.\n",
        "> * Abreviaturas típicas que se dan en grupos de whatsapp debido a la informalidad de los mensajes, por la  expresión completa a la cual refieren.\n",
        "> * Repeticiones de 3 o más veces seguidas de una misma letra por dicha letra una única vez. Esto debido a que no existen en nuestro idioma palabras con la misma letra seguida 3 veces o más.\n",
        "> * Dos o más espacios por uno solo.\n",
        "> * Números por su expresión escrita en palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13BKYLY-zd8L"
      },
      "source": [
        "Dado el objeto \"chat_lista\" obtenido luego de la carga del chat de Whatsapp, en la sección anterior, para poder preprocesar los mensajes obtenidos de forma adecuada, debemos primero eliminar metadatos de la lista, como la fecha y el autor. También eliminamos mensajes vacíos que no van a poder ser preprocesados, y realizamos una codificación con posterior decodificación en UTF-8, de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrGuMnxMuhAz"
      },
      "outputs": [],
      "source": [
        "# Eliminamos el texto antes de los dos puntos, es decir los metadatos correspondientes a fecha y autor.\n",
        "for i in range(len(chat_lista)):\n",
        "    chat_lista[i][0] = re.sub(r'.*?: ', '', chat_lista[i][0])\n",
        "# Removemos mensajes vacíos\n",
        "chat_lista = [item for item in chat_lista if item[0].strip()]\n",
        "# Codificamos y decodificamos el texto en UTF-8\n",
        "for i in range(len(chat_lista)):\n",
        "    chat_lista[i][0] = chat_lista[i][0].encode('utf-8', 'ignore').decode('utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a4M80k5jc9R",
        "outputId": "9d1b20a2-6fd9-4bec-d969-9c8c3f72cce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\u200eLos mensajes y las llamadas están cifrados de extremo a extremo. Nadie fuera de este chat, ni siquiera WhatsApp, puede leerlos ni escucharlos.\\n']\n"
          ]
        }
      ],
      "source": [
        "print(chat_lista[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOCWy0emMdPS"
      },
      "source": [
        "Instalamos e importamos la biblioteca que nos permitirá reemplazar números por su correspondiente expresión en letras en nuestro preprocesamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBH46VhkiGtr"
      },
      "outputs": [],
      "source": [
        "!pip install num2words\n",
        "from num2words import num2words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_tJfxdzNIms",
        "outputId": "defa2d45-fbd5-4362-9f0f-48b3f58b3640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "veinticuatro mil novecientos veinte\n",
            "menos nueve\n",
            "uno punto cuatro\n"
          ]
        }
      ],
      "source": [
        "### Ejemplo de uso num2words:\n",
        "print(num2words(\"24920\", lang='es'))\n",
        "print(num2words(\"-9\", lang='es'))\n",
        "print(num2words(\"1.4\", lang='es'))\n",
        "\n",
        "# Debemos controlar previamente que el valor a convertir sea numérico.\n",
        "# Esto lo hacemos mediante la función .isnumeric() como se puede ver en\n",
        "# reemplazar_numeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mim5M_gNF1B"
      },
      "source": [
        "#### Funciones de preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2kOeMA_ly_b"
      },
      "outputs": [],
      "source": [
        "# Preprocesamiento de los mensajes de Whatsapp\n",
        "\n",
        "# reemplazar_URL(texto):\n",
        "# Reemplaza las URL del texto recibido por parámetro por el string vacío.\n",
        "def reemplazar_URL(texto):\n",
        "    texto2 = re.sub(r\"http[s]?://(?:[a-zA-Z]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \"\", texto)\n",
        "    return texto2\n",
        "\n",
        "# Segunda pasada\n",
        "def eliminar_url(texto):\n",
        "    patron_url = r'http'\n",
        "    texto_limpio = re.sub(patron_url, '', texto)\n",
        "    return texto_limpio\n",
        "\n",
        "def eliminar_notificaciones(texto):\n",
        "    patrones = [\n",
        "      r\"creó este grupo.\",\n",
        "      r\"se unió usando el enlace de invitación\",\n",
        "      r\"los mensajes y las llamadas están cifrados\",\n",
        "      r\"te uniste mediante el enlace de invitación de este grupo\",\n",
        "      r\"cambió su número de teléfono\",\n",
        "      r\"se añadió a\",\n",
        "      r\"cambió el asunto a\",\n",
        "      r\"los mensajes y las llamadas están cifrados de extremo a extremo nadie fuera de este chat ni siquiera puede leerlos ni escucharlos\",\n",
        "      r\"se eliminó este mensaje\"\n",
        "    ]\n",
        "\n",
        "    # Combinamos todos los patrones en una única expresión regular\n",
        "    # patron_combinado = r'' + '|'.join(patrones)\n",
        "    patron_combinado = \"|\".join(patrones)\n",
        "\n",
        "    if re.search(patron_combinado, texto):\n",
        "        return \"\"\n",
        "    else:\n",
        "        # Eliminamos caracteres relacionados a datos que no son palabras\n",
        "        texto = texto.replace('\\u200e', '')\n",
        "        texto = texto.replace('\\u202c', '')\n",
        "        texto = texto.replace('\\u202a', '')\n",
        "        return texto\n",
        "\n",
        "\n",
        "# reemplazar_Abreviaturas(texto):\n",
        "# Remplazar abreviaturas comunes por el término original.\n",
        "def reemplazar_Abreviaturas(texto):\n",
        "    texto2 = re.sub(r'[\\s^][xX][qQ][\\s$]',' porque ', texto)\n",
        "    texto2 = re.sub(r'[\\s^][pP](\\s)*[qQ][\\s$]',' porque ', texto2)\n",
        "    texto2 = re.sub(r'porq',' porque ', texto2)\n",
        "    texto2 = re.sub('[\\s^][xX][\\s$]',' por ', texto2)\n",
        "    texto2 = re.sub('[\\s^][qQ][\\s$]',' que ', texto2)\n",
        "    texto2 = re.sub('[\\s^][kK][\\s$]',' que ', texto2)\n",
        "    texto2 = re.sub('[\\s^][bB][nN][\\s$]',' bien ', texto2)\n",
        "    texto2 = re.sub('[\\s^][tT][mM][bB][\\s$]',' tambien ', texto2)\n",
        "    texto2 = re.sub('[\\s^][aA][cC][eE][Ss][\\s$]',' haces ', texto2)\n",
        "    texto2 = re.sub('[\\s^][bB][bB][\\?*\\s$]',' bebé ', texto2)\n",
        "    texto2 = re.sub('[\\s^][bB][bB][sS][\\?*\\s$]',' bebés ', texto2)\n",
        "    texto2 = re.sub('[\\s^][vV][sS][\\s$]',' versus ', texto2)\n",
        "    texto2 = re.sub('[\\s^][cC][\\s$]',' se ', texto2)\n",
        "    texto2 = re.sub('[\\s^]\\+[\\s$]',' mas ', texto2)\n",
        "    texto2 = re.sub('[\\s^][dD][\\s$]',' de ', texto2)\n",
        "    texto2 = re.sub('[\\s^][dD][lL][\\s$]',' del ', texto2)\n",
        "    texto2 = re.sub('[\\s^][tT][aA][\\s$]',' está ', texto2)\n",
        "    texto2 = re.sub('[\\s^][pP][aA][\\s$]',' para ', texto2)\n",
        "    texto2 = re.sub('[\\s^][pP][sS][\\?*\\.*\\,*\\s$]',' pues ', texto2)\n",
        "    texto2 = re.sub('[\\s^][mM][\\s$]',' me ', texto2)\n",
        "    texto2 = re.sub('[\\s^][cC][sS][mM][\\s$]',' insulto ', texto2)  #Cambiamos csm por insulto.\n",
        "    texto2 = re.sub('[\\s^][gG]ral[\\s.$]',' general ', texto2)\n",
        "    texto2 = re.sub('[\\s^][dD][rR][.\\s$]',' doctor ', texto2)\n",
        "    texto2 = re.sub('[\\s^][mM][gG][\\s$]',' me gusta ', texto2)\n",
        "    texto2 = re.sub(r'(a+)h+', 'ah', texto2)\n",
        "    return texto2\n",
        "\n",
        "\n",
        "# reemplazar_Risa(texto):\n",
        "# Remplazar en este caso las variantes posibles de una risa (expresion frecuente) por el String \"jajaja\".\n",
        "# De esta forma, homogenizamos las risas\n",
        "def reemplazar_Risa(texto):\n",
        "    er_risa = r'\\b([aA]+[jJ]+[aA]+[aAjJ]*|[jJ]+[jaJA]+[jJ]+[jaJA]*|[aA]+[hH]+[aA]+[aAhH]*|[hH]+[haHA]+[hH]+[haHA]*|[oO]?[lL]+[oO]+[lL]+[oLOl]*|[aA]*[jaJA]+[jJ][jJAa]*|[eE]+[jJ]+[eE]+[eEjJ]*|[jJ]+[jeJE]+[jJ]+[jeJE]*|[eE]+[hH]+[eE]+[eEhH]*|[hH]+[heHE]+[hH]+[heHE]*|[eE]*[jeJE]+[jJ][jJeE]*)\\b'\n",
        "    texto2 = re.sub(er_risa,' jajaja ', texto)\n",
        "    return texto2\n",
        "\n",
        "\n",
        "# reemplazar_repeticiones(texto)\n",
        "# Reemplaza las repeticiones de 3 o más veces la misma letra por una sola en \"texto\"\n",
        "def reemplazar_repeticiones(texto):\n",
        "    texto = re.sub(\"aaa[a]*\",\"a\",texto)\n",
        "    texto = re.sub(\"bbb[b]*\",\"b\",texto)\n",
        "    texto = re.sub(\"ccc[c]*\",\"c\",texto)\n",
        "    texto = re.sub(\"ddd[a]*\",\"d\",texto)\n",
        "    texto = re.sub(\"eee[e]*\",\"e\",texto)\n",
        "    texto = re.sub(\"fff[f]*\",\"f\",texto)\n",
        "    texto = re.sub(\"ggg[g]*\",\"g\",texto)\n",
        "    texto = re.sub(\"hhh[h]*\",\"h\",texto)\n",
        "    texto = re.sub(\"iii[i]*\",\"i\",texto)\n",
        "    texto = re.sub(\"jjj[j]*\",\"j\",texto)\n",
        "    texto = re.sub(\"kkk[k]*\",\"k\",texto)\n",
        "    texto = re.sub(\"lll[l]*\",\"l\",texto)\n",
        "    texto = re.sub(\"mmm[m]*\",\"m\",texto)\n",
        "    texto = re.sub(\"nnn[n]*\",\"n\",texto)\n",
        "    texto = re.sub(\"ooo[o]*\",\"o\",texto)\n",
        "    texto = re.sub(\"ppp[p]*\",\"p\",texto)\n",
        "    texto = re.sub(\"qqq[q]*\",\"q\",texto)\n",
        "    texto = re.sub(\"rrr[r]*\",\"r\",texto)\n",
        "    texto = re.sub(\"sss[s]*\",\"s\",texto)\n",
        "    texto = re.sub(\"ttt[t]*\",\"t\",texto)\n",
        "    texto = re.sub(\"uuu[u]*\",\"u\",texto)\n",
        "    texto = re.sub(\"vvv[v]*\",\"v\",texto)\n",
        "    texto = re.sub(\"www[w]*\",\"w\",texto)  #Luego de Urls\n",
        "    texto = re.sub(\"xxx[x]*\",\"x\",texto)\n",
        "    texto = re.sub(\"yyy[y]*\",\"y\",texto)\n",
        "    texto = re.sub(\"zzz[z]*\",\"z\",texto)\n",
        "    return texto\n",
        "\n",
        "# Reemplazamos los números de todos los mensajes\n",
        "# por su correspondiente Palabra\n",
        "def reemplazar_numeros(texto):\n",
        "    palabras = []\n",
        "    palabras_originales = texto.split()\n",
        "    for palabra in palabras_originales:\n",
        "        if palabra.isnumeric():\n",
        "            try:\n",
        "              palabra_convertida = num2words(palabra, lang='es')\n",
        "              palabras.append(palabra_convertida)\n",
        "            except:\n",
        "              palabras.append(palabra)\n",
        "        else:\n",
        "            palabras.append(palabra)\n",
        "    texto_convertido = ' '.join(palabras)\n",
        "    return texto_convertido\n",
        "\n",
        "# Removemos saltos de línea reemplazandolos por espacios\n",
        "def remover_saltos_de_linea(texto):\n",
        "  patron_saltos = r'\\n'\n",
        "  texto = re.sub(patron_saltos, \" \", texto)\n",
        "  return texto\n",
        "\n",
        "# Reemplazamos 2 o mas espacios seguidos por uno solo\n",
        "def remover_espacios(texto):\n",
        "  patron_espacios = r'\\s+'\n",
        "  texto = re.sub(patron_espacios, \" \", texto)\n",
        "  return texto\n",
        "\n",
        "# Removemos mensajes que aparecen debido a que no se recuperan archivos al exportar el chat.\n",
        "def remover_omitidos(texto):\n",
        "  resultado = re.sub('sticker omitido','',texto)\n",
        "  resultado = re.sub('audio omitido','',resultado)\n",
        "  resultado = re.sub('imagen omitida','',resultado)\n",
        "  resultado = re.sub('documento omitido','',resultado)\n",
        "  resultado = re.sub('multimedia omitido','',resultado)\n",
        "  return resultado\n",
        "\n",
        "\n",
        "# Removemos caracteres que no son alfanuméricos,\n",
        "# no son espacios en blanco y no son letras con tildes.\n",
        "def remover_signos_puntuacion_excepto_tildes(text):\n",
        "    return re.sub(r'[^\\w\\sáéíóúÁÉÍÓÚ]', '', text)\n",
        "\n",
        "def cruzar_diccionario(frase):\n",
        "    texto = [word for word in frase.split() if word in diccionario]\n",
        "    frase_filtrada = ' '.join(texto)\n",
        "    return frase_filtrada\n",
        "\n",
        "\n",
        "# Aplicamos todas las funciones anteriores para procesar los mensajes\n",
        "# y retornamos el resultado.\n",
        "def procesar_texto(mensaje):\n",
        "    if (mensaje in ['',' ']):\n",
        "      return ''\n",
        "    contenido = \"\"\n",
        "    contenido = mensaje\n",
        "    contenido = contenido.lower()\n",
        "    contenido = reemplazar_numeros(contenido)\n",
        "    contenido = eliminar_notificaciones(contenido)\n",
        "    contenido = reemplazar_URL(contenido)\n",
        "    contenido = remover_omitidos(contenido)\n",
        "    contenido = remover_saltos_de_linea(contenido)\n",
        "    contenido = eliminar_url(contenido)\n",
        "    contenido = reemplazar_repeticiones(contenido)\n",
        "    contenido= reemplazar_Abreviaturas(contenido)\n",
        "    contenido = reemplazar_Risa(contenido)\n",
        "    contenido = remover_signos_puntuacion_excepto_tildes(contenido)\n",
        "    contenido = remover_espacios(contenido)  #Se reemplazan varios espacios seguidos por uno solo. Debe ir ultima\n",
        "    contenido = cruzar_diccionario(contenido)\n",
        "    return contenido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2juQhZMMOdCx"
      },
      "source": [
        "## 3.2 Algoritmo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DThUp03wOeAo"
      },
      "source": [
        "### 3.2.1 Implementación bayesiana por conteo de palabras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZlYX4F9LPdi"
      },
      "source": [
        "\n",
        "Implementamos una extensión del algoritmo Naive Bayes, donde asumimos independencia en el orden de aparición solamente de las N últimas palabras de la frase que se esté considerando. En caso de que la frase tenga menos que 'N' palabras, se considerarán todas ellas solamente. Otra posibilidad era rellenar aquellas frases que no tuvieran largo 'N', pero decidimos optar por el enfoque anterior ya que estaría perjudicando la predicción al agregar en el cálculo productos que no se corresponden con la frase original.\n",
        "\n",
        "A su vez, el algoritmo agrega las etiquetas 'START' y 'END' al inicio y fin respectivamente de cada frase que permite entrenar el algoritmo. Esto lo hacemos para que se puedan considerar correctamente todas las palabras de la frase, por pares. A su vez, se decide que la palabra 'END' tenga una probabilidad previa muy baja:\n",
        "\n",
        "$$ P(<END>) = \\frac{  1 \\times 10^{-10}}{\\# apariciones-de-palabras}$$\n",
        "\\\n",
        "Esto es debido a que siempre queremos predecir una palabra real al estar trabajando con frases.\n",
        "\n",
        "Por otro lado, se aplica la técnica de suavizado para tratar con palabras que no aparecieron en el entrenamiento, evitando probabilidades iguales a cero.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFzGsR-qBM8V"
      },
      "outputs": [],
      "source": [
        "class NaiveBayesPredictor:\n",
        "    def __init__(self, N=1):\n",
        "        # Guardamos el hiperparametro del metodo\n",
        "        self.N = N\n",
        "        # 'modelo' es un diccionario cuyas claves son palabras individuales del conjunto de entrenamiento\n",
        "        # y cuyos valores son contadores (Counter) que rastrean cuántas veces otras palabras aparecen\n",
        "        # después de esa palabra clave en el conjunto de entrenamiento\n",
        "        self.modelo = defaultdict(Counter)\n",
        "        # 'apariciones' es un diccionario que rastrea cuántas veces ha aparecido cada palabra en el conjunto de entrenamiento.\n",
        "        # El mismo sera utilizado para obtener la Probabilidad a priori/previa de una candidata a ser la proxima.\n",
        "        self.apariciones = defaultdict(int)\n",
        "        # 'vocabulario' es un conjunto que contiene todas las palabras únicas que el modelo ha visto durante el entrenamiento\n",
        "        self.vocabulario = set()\n",
        "\n",
        "    def train(self, frases):\n",
        "        for frase in frases:\n",
        "            tokens = frase.split()         # Separamos por palabras la frase\n",
        "            tokens = [token for token in tokens if token in diccionario] # Trabajamos solo con palabras correctas.\n",
        "            # Agregamos dos palabras 'ficticias' para manejar el comienzo y final de los mensajes\n",
        "            tokens = ['<START>'] + tokens + ['<END>']\n",
        "            for i in range(len(tokens) - 1):         # Consideramos pares de palabras\n",
        "                history_word = tokens[i]\n",
        "                next_word = tokens[i+1]\n",
        "                self.modelo[history_word][next_word] += 1\n",
        "                self.apariciones[history_word] += 1\n",
        "                self.vocabulario.add(next_word)\n",
        "\n",
        "    def predict(self, frase):\n",
        "        tokens = frase.split()\n",
        "        max_prob = float('-inf')   # Inicializamos, queremos la palabra que maximizara este valor.\n",
        "        mejor_palabra = None\n",
        "        V = len(self.vocabulario)\n",
        "        candidatos = []           # Para etapa de evaluacion, almacenamos pares palabra y log_probabilidad de ser la siguiente\n",
        "        for candidata in self.vocabulario:\n",
        "            log_prob = 0\n",
        "            for palabra_previa in tokens[-self.N:]:\n",
        "                # Ahora, estamos obteniendo el número de veces que la palabra 'candidata' ha aparecido después\n",
        "                # de la palabra_previa en el conjunto de entrenamiento. Si la combinación\n",
        "                # de palabra_previa y candidata no se encuentra en el modelo (lo que podría suceder si\n",
        "                # no apareció en el conjunto de entrenamiento), se devuelve un valor predeterminado de 0.\n",
        "                apariciones_par = self.modelo[palabra_previa].get(candidata, 0)\n",
        "                # Luego, obtenemos el número total de veces que la palabra_previa\n",
        "                # ha aparecido en el conjunto de entrenamiento. Es decir, la probabilidad previa\n",
        "                apariciones_palabra_previa = self.apariciones.get(palabra_previa, 0)\n",
        "                # Aplicamos la tecnica de suavizado para tratar con las palabras que no aparecieron al entrenar.\n",
        "                # A su vez, sumamos logaritmos para combatir el underflow.\n",
        "                # Obtenemos P(palabra_previa ∣ candidata).\n",
        "                log_prob += math.log((apariciones_par + 1) / (apariciones_palabra_previa + V))\n",
        "\n",
        "            # Probabilidad a priori de la palabra. Sin suavizado porque consideramos palabras del Vocabulario.\n",
        "            # Como la funcion logaritmo no existe en el cero, ponemos 1e-10, pero como estamos considerando\n",
        "            # solamente palabras vistas en el entrenamiento, sabemos que total_counts.get(word) > 0\n",
        "            # para todas ellas excepto '<END>', quien obtendra la peor probabilidad a priori. Esto es deseable\n",
        "            # ya que queremos predecir siempre una proxima palabra mientras la oracion no haya finalizado.\n",
        "            log_prob += math.log((self.apariciones.get(candidata, 1e-10) ) / (sum(self.apariciones.values())))\n",
        "            candidatos.append((candidata, round(log_prob, 2)))\n",
        "\n",
        "            if log_prob > max_prob:\n",
        "                max_prob = log_prob\n",
        "                mejor_palabra = candidata\n",
        "        # Retornamos las 3 palabras mas probables de ser la siguiente dada la frase en cuestion.\n",
        "        # Estan ordenadas de menor a mayor\n",
        "        candidatos_sorted = sorted(candidatos, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return candidatos_sorted[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9el28f6bOaZh"
      },
      "source": [
        "### 3.2.2 Implementación bayesiana con TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFFsbAsqQHsA"
      },
      "source": [
        "Mediante experimentación subjetiva con la implementación anterior, observamos que se recomienda una alta cantidad de \"stop-words\" a la hora de predecir cualquier palabra. Por lo tanto, consideramos también que puede resultar interesante una implementación del algoritmo bayesiano pero esta vez en vez de tomar las probabilidades basándonos en el conteo de palabras, lo hacemos en el índice TF-IDF de las palabras en cada oración del corpus:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iC0n5G6R_Ko"
      },
      "source": [
        "La probabilidad a priori cde cada palabra es:\n",
        "\n",
        "\n",
        "$$ P(w) = \\frac{1 \\times 10^{-10} + \\sum_{i\\in D}{TFIDF}_i(w)}{|D|}$$\n",
        "\n",
        "siendo D nuestro conjunto de mensajes, por lo que cada elemento $i$ de este conjunto será un mensaje. En caso de que la palabra en cuestión sea una etiqueta START o END, tomamos:\n",
        "\n",
        "$$ P(<START>) = \\frac{1 \\times 10^{-10}}{|D|}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5auHfomJGotv"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import math\n",
        "\n",
        "class NaiveBayesPredictor_TFIDF:\n",
        "    def __init__(self, N=1):\n",
        "        # Hiperparámetro del método:\n",
        "        self.N = N\n",
        "        # Diccionario: (palabra) -> (Puntajes tf-idf)\n",
        "        self.modelo = defaultdict(dict)\n",
        "        # Este atributo construye las matrices tf-idf que vamos a usar\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        # Conjunto de todas las palabras procesadas al entrenar\n",
        "        self.vocabulario = set()\n",
        "        self.vocab_negativo = set()\n",
        "        # Conjunto que mantiene las palabras aprendidas por el modelo.\n",
        "        # Facilitará el hecho de cumplir con el requisito de que sea posible\n",
        "        # entrenar el modelo al realizar predicciones.\n",
        "        self.apariciones = defaultdict(int)\n",
        "        self.corpus = []\n",
        "\n",
        "    def train(self, frases):\n",
        "        # Transformamos las frases en una matriz TF-IDF\n",
        "        corpus_total = frases + self.corpus\n",
        "        X = self.vectorizer.fit_transform(corpus_total)\n",
        "        # Obtenemos los nombres de las features, es decir, las palabras en el corpus\n",
        "        feature_names = list(self.vectorizer.get_feature_names_out())\n",
        "\n",
        "        for i in range (len(corpus_total)):\n",
        "\n",
        "            frase = corpus_total[i]\n",
        "            tokens = frase.split()\n",
        "            # tokens = [token for token in tokens if token in diccionario]\n",
        "            tokens = ['<START>'] + tokens + ['<END>']\n",
        "\n",
        "            for j in range(len(tokens) - 1):      # Para cada par de palabras:\n",
        "                history_word = tokens[j]\n",
        "                next_word = tokens[j+1]\n",
        "\n",
        "                if history_word in feature_names and next_word in feature_names:\n",
        "\n",
        "                    history_word_idx = feature_names.index(history_word)\n",
        "                    next_word_idx = feature_names.index(next_word)\n",
        "\n",
        "                    # Almacena la puntuación TF-IDF de la palabra siguiente condicionada por la palabra previa\n",
        "                    self.modelo[history_word][next_word] = X[i, next_word_idx]\n",
        "\n",
        "                    self.vocabulario.add(next_word)\n",
        "                else: # si el modelo tf-idf no las reconoce, ignoramos la palabra.\n",
        "                    self.vocab_negativo.add(next_word)\n",
        "        self.corpus = corpus_total\n",
        "\n",
        "    def predict(self, frase,numero_candidatos=3):\n",
        "        tokens = frase.split()\n",
        "        max_prob = float('-inf')\n",
        "        candidatos = []\n",
        "        for candidata in self.vocabulario:\n",
        "          log_prob = 0\n",
        "          for palabra_previa in tokens[-self.N:]:\n",
        "              # Obtiene la puntuación TF-IDF de la palabra candidata condicionada por la palabra previa\n",
        "              tfidf_score = self.modelo[palabra_previa].get(candidata, 0)\n",
        "              # Aplicamos logaritmo a la puntuación TF-IDF para evitar underflow\n",
        "              log_prob += math.log(tfidf_score + 1e-10)\n",
        "          # Probabilidad a priori de la palabra:\n",
        "          log_prob += math.log((sum(self.modelo[candidata].values()) + 1e-10) / len(self.corpus))\n",
        "          candidatos.append((candidata, round(log_prob, 2)))\n",
        "          if log_prob > max_prob:\n",
        "              max_prob = log_prob\n",
        "\n",
        "        candidatos_sorted = sorted(candidatos, key=lambda x: x[1], reverse=True)\n",
        "        return candidatos_sorted[:numero_candidatos]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxfRcJikPrWp"
      },
      "source": [
        "#### 3.2.2.1 Corroboramos las capacidades de nuestro algoritmo TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIJaREDtBV-v",
        "outputId": "509fd79b-1298-4d52-df14-5f03135dab39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['días', 'buenos']\n",
            "['<END>', 'hola']\n"
          ]
        }
      ],
      "source": [
        "predictor = NaiveBayesPredictor_TFIDF(3)\n",
        "predictor.train([\"hola buenos días\"])\n",
        "print(list(predictor.vocabulario))\n",
        "print(list(predictor.vocab_negativo))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV9P7mgw2e8-",
        "outputId": "1e8a5c93-d452-4463-d96f-2bb0a01ef502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['días', 'buenas', 'buenos', 'tardes']\n",
            "['<END>', 'hola']\n"
          ]
        }
      ],
      "source": [
        "predictor.train([\"hola buenas tardes\"])\n",
        "print(list(predictor.vocabulario))\n",
        "print(list(predictor.vocab_negativo))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZE4AZbF2nH9"
      },
      "source": [
        "Como se puede observar, entrenamos el modelo nuevamente en la segunda celda y este recuerda las palabras del primer entrenamiento, esto hace posible el entrenar mientras se utiliza el modelo, como se especifica en la letra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0VaEJ2lYzTk"
      },
      "source": [
        "\n",
        "\n",
        "## 3.3 Evaluación\n",
        "\n",
        "Corpus de entrenamiento:\n",
        "\n",
        "* Entrenaremos nuestros dos algoritmos con dos corpus de mensajes:\n",
        "\n",
        ">* Formal1: Se trata de un chat de un grupo general de una materia de la facultad, por lo tanto, el lenguaje que se utiliza aquí es un lenguaje con un nivel medio de formalidad, en el que no encontraremos groserías o expresiones vulgares. Este grupo tiene cerca de 2000 mensajes de los cuales aproximadamente descartamos 300 en el preprocesamiento.\n",
        "\n",
        ">* Informal1: Se trata de un chat de un grupo ocioso no relacionado con el estudio, elegimos agregar este chat ya que puede resultar interesante comparar distintas implementaciones y métricas en grupos de distinta naturaleza y tamaño. Este chat cuenta con cerca de 30.000 mensajes.\n",
        "\n",
        "- Para evaluar los algoritmos optamos por estos dos métodos:\n",
        "\n",
        "> *  Comparación subjetiva:\n",
        ">> Analizaremos si ciertas predicciones tienen sentido, comparando con las otras predicciones candidatas que tenían mayores probabilidades de convertirse en la predicción que se iba a terminar sugiriendo.\n",
        "\n",
        "\n",
        "> * Evaluaremos la precisión del algoritmo para predecir la última palabra de un subconjunto de mensajes de los conjuntos presentados anteriormente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bJLygILsCmN"
      },
      "source": [
        "Antes de presentar la función de evaluación para uno de los métodos presentados en el punto anterior, generamos las estructuras que nos permitirán llevar a cabo las pruebas. Dado el chat que se cargue con nombre: \"_chat\", tal cual es generado por Whatsapp, generamos el objeto \"data\" aplicando el correspondiente pre-procesamiento a cada mensaje de \"chat_lista\" que contiene los mensajes de Whatsapp sin metadatos y en formato 'UTF-8'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBfGhU7D4j5H",
        "outputId": "e91fa9d4-6fd0-4c0c-dfaf-fd2a4a0f1aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Primer mensaje del nuevo corpus: \n",
            "hola de este curso las que van a haber son las de los no\n",
            "\n",
            "Se eliminaron 344 mensajes en el preprocesamiento\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "for elemento in chat_lista:\n",
        "  elemento = procesar_texto(elemento[0])\n",
        "  if (elemento != '') and (elemento != ' '):\n",
        "    data.append(elemento)\n",
        "print(\"Primer mensaje del nuevo corpus: \")\n",
        "print(data[0])\n",
        "print(\"\\nSe eliminaron \"+str((len(chat_lista) - len(data))) + \" mensajes en el preprocesamiento\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr9gyk5W7M7U"
      },
      "source": [
        "### 3.3.1 Función de evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqwLkAt_mH6u"
      },
      "outputs": [],
      "source": [
        "def evaluar_predictor(porcentaje_entrenamiento, frases, n,tipo_pred=\"normal\"):\n",
        "    \"\"\"\n",
        "    Evalúamos la precisión del predictor implementado de Naive Bayes al intentar predecir la última palabra de las frases.\n",
        "    Argumentos:\n",
        "    - predictor: Una instancia de un predictor de Naive Bayes.\n",
        "    - porcentaje_entrenamiento: Porcentaje de frases a utilizar para entrenamiento.\n",
        "    - frases: Una lista de frases a utilizar.\n",
        "    - n : Hiperparametro del predictor\n",
        "    Retorno:\n",
        "    - Precisión del predictor.\n",
        "    \"\"\"\n",
        "    # Mezclamos las frases del conjunto:\n",
        "    random.shuffle(frases)\n",
        "    # Dividimos las frases en conjuntos de entrenamiento y prueba\n",
        "    n_entrenamiento = int(porcentaje_entrenamiento * len(frases))\n",
        "    frases_entrenamiento = frases[:n_entrenamiento]\n",
        "    frases_prueba = frases[n_entrenamiento:]\n",
        "    if tipo_pred == \"tf_idf\":\n",
        "      predictor = NaiveBayesPredictor_TFIDF(n)\n",
        "    else:\n",
        "      predictor = NaiveBayesPredictor(n)\n",
        "    predictor.train(frases_entrenamiento)\n",
        "    correctas = 0\n",
        "    total = 0\n",
        "    for frase in frases_prueba:\n",
        "        tokens = frase.split()\n",
        "        if len(tokens) == 0:  # Salteamos frases vacías\n",
        "            continue\n",
        "        palabra_real = tokens[-1]  # Extraemos la ultima palabra de la frase\n",
        "        prediccion = None\n",
        "        if tipo_pred == \"tf_idf\":\n",
        "          prediccion = predictor.predict(' '.join(tokens[:-1]),3) #[:-1] parq ue tome todos los tokens excepto el ultimo\n",
        "        else:\n",
        "          prediccion = predictor.predict(' '.join(tokens[:-1])) #[:-1] parq ue tome todos los tokens excepto el ultimo\n",
        "        palabra_predicha = prediccion[0][0]\n",
        "        if palabra_real == palabra_predicha:\n",
        "            correctas += 1\n",
        "        total += 1\n",
        "\n",
        "    # Calculamos la precisión y la retornamos\n",
        "    precision = correctas / total\n",
        "    print(\"Se obtuvo una precisión de: \",precision)\n",
        "    return precision\n",
        "\n",
        "# Dada una lista de frases, imprimimos las recomendaciones de siguiente palabra que brinda el modelo\n",
        "def predecir_palabras(lista,predictor,cantidad=3,tipo_pred=\"conteo\"):\n",
        "  for frase in lista:\n",
        "    siguiente_palabra = None\n",
        "    if tipo_pred == \"tf-idf\":\n",
        "      siguiente_palabra = predictor.predict(frase,cantidad)\n",
        "    else:\n",
        "      siguiente_palabra = predictor.predict(frase)\n",
        "    elegida = siguiente_palabra[0][0]\n",
        "    print(f\"La palabra predicha después de '{frase}' es: '{elegida}' dadas las probabilidades obtenidas: '{siguiente_palabra}'\")\n",
        "\n",
        "def evaluar_lista(n_elegidos,frases,datos_train,tipo_pred=\"conteo\"):\n",
        "  for n in n_elegidos:\n",
        "    if tipo_pred == 'tf_idf':\n",
        "      predictor = NaiveBayesPredictor_TFIDF(n)\n",
        "    else:\n",
        "      predictor = NaiveBayesPredictor(n)\n",
        "    predictor.train(datos_train) #Entrenamos con el grupo de Whatsapp\n",
        "    for frase in frases:\n",
        "      if tipo_pred == 'tf_idf':\n",
        "        siguiente_palabra = predictor.predict(frase,3)\n",
        "      else:\n",
        "        siguiente_palabra = predictor.predict(frase)\n",
        "      elegida = siguiente_palabra[0][0]\n",
        "      print(f\"La palabra predicha después de '{frase}' es: '{elegida}' para N = {n}\")\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoMaBWQTLPdi"
      },
      "source": [
        "# 4. Experimentación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGX6m7bal1P1"
      },
      "source": [
        "## 4.1 Método Subjetivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2WWayDoQDFC"
      },
      "source": [
        "### 4.1.1 Implementación bayesiana por conteo de palabras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqJn14Ntl6gh"
      },
      "source": [
        "A continuación, analizaremos el comportamiento del primer algoritmo para los valores de N: 1, 2, 3 y 4. A su vez, tomaremos un subconjunto de frases que consideramos muy usuales en las conversaciones de Whatsapp. También consideramos la frase: \"\", por más que no es posible enviarla a través de la app, pero nos resultaba interesante analizar cuál es la palabra más frecuente en el inicio de los mensajes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1_u5biio9mW"
      },
      "outputs": [],
      "source": [
        "data_evaluar_lista = data.copy()\n",
        "lista_predict = [\"\",\"hola\",\"por\",\"hoy\",\"también\",\"quien\",\"puedo\",\"yo\",\"no\",\"yo no\",\"quien no\",\"a que\",\"el martes\",\"que sale\",\"a que hora\",\"por las dudas\",\"no se si el\",\"yo no creo que\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXvsytfNkD99",
        "outputId": "4f9f6fd1-2272-4546-cb2c-cd707d44ffc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La palabra predicha después de '' es: 'que' para N = 1\n",
            "La palabra predicha después de 'hola' es: 'a' para N = 1\n",
            "La palabra predicha después de 'por' es: 'que' para N = 1\n",
            "La palabra predicha después de 'hoy' es: 'no' para N = 1\n",
            "La palabra predicha después de 'también' es: 'de' para N = 1\n",
            "La palabra predicha después de 'quien' es: 'no' para N = 1\n",
            "La palabra predicha después de 'puedo' es: 'de' para N = 1\n",
            "La palabra predicha después de 'yo' es: 'que' para N = 1\n",
            "La palabra predicha después de 'no' es: 'se' para N = 1\n",
            "La palabra predicha después de 'yo no' es: 'se' para N = 1\n",
            "La palabra predicha después de 'quien no' es: 'se' para N = 1\n",
            "La palabra predicha después de 'a que' es: 'no' para N = 1\n",
            "La palabra predicha después de 'el martes' es: 'y' para N = 1\n",
            "La palabra predicha después de 'que sale' es: 'el' para N = 1\n",
            "La palabra predicha después de 'a que hora' es: 'que' para N = 1\n",
            "La palabra predicha después de 'por las dudas' es: 'que' para N = 1\n",
            "La palabra predicha después de 'no se si el' es: 'de' para N = 1\n",
            "La palabra predicha después de 'yo no creo que' es: 'no' para N = 1\n",
            "La palabra predicha después de '' es: 'que' para N = 2\n",
            "La palabra predicha después de 'hola' es: 'a' para N = 2\n",
            "La palabra predicha después de 'por' es: 'que' para N = 2\n",
            "La palabra predicha después de 'hoy' es: 'no' para N = 2\n",
            "La palabra predicha después de 'también' es: 'de' para N = 2\n",
            "La palabra predicha después de 'quien' es: 'no' para N = 2\n",
            "La palabra predicha después de 'puedo' es: 'de' para N = 2\n",
            "La palabra predicha después de 'yo' es: 'que' para N = 2\n",
            "La palabra predicha después de 'no' es: 'se' para N = 2\n",
            "La palabra predicha después de 'yo no' es: 'es' para N = 2\n",
            "La palabra predicha después de 'quien no' es: 'se' para N = 2\n",
            "La palabra predicha después de 'a que' es: 'la' para N = 2\n",
            "La palabra predicha después de 'el martes' es: 'de' para N = 2\n",
            "La palabra predicha después de 'que sale' es: 'no' para N = 2\n",
            "La palabra predicha después de 'a que hora' es: 'no' para N = 2\n",
            "La palabra predicha después de 'por las dudas' es: 'de' para N = 2\n",
            "La palabra predicha después de 'no se si el' es: 'de' para N = 2\n",
            "La palabra predicha después de 'yo no creo que' es: 'que' para N = 2\n",
            "La palabra predicha después de '' es: 'que' para N = 3\n",
            "La palabra predicha después de 'hola' es: 'a' para N = 3\n",
            "La palabra predicha después de 'por' es: 'que' para N = 3\n",
            "La palabra predicha después de 'hoy' es: 'no' para N = 3\n",
            "La palabra predicha después de 'también' es: 'de' para N = 3\n",
            "La palabra predicha después de 'quien' es: 'no' para N = 3\n",
            "La palabra predicha después de 'puedo' es: 'de' para N = 3\n",
            "La palabra predicha después de 'yo' es: 'que' para N = 3\n",
            "La palabra predicha después de 'no' es: 'se' para N = 3\n",
            "La palabra predicha después de 'yo no' es: 'es' para N = 3\n",
            "La palabra predicha después de 'quien no' es: 'se' para N = 3\n",
            "La palabra predicha después de 'a que' es: 'la' para N = 3\n",
            "La palabra predicha después de 'el martes' es: 'de' para N = 3\n",
            "La palabra predicha después de 'que sale' es: 'no' para N = 3\n",
            "La palabra predicha después de 'a que hora' es: 'la' para N = 3\n",
            "La palabra predicha después de 'por las dudas' es: 'que' para N = 3\n",
            "La palabra predicha después de 'no se si el' es: 'que' para N = 3\n",
            "La palabra predicha después de 'yo no creo que' es: 'se' para N = 3\n",
            "La palabra predicha después de '' es: 'que' para N = 4\n",
            "La palabra predicha después de 'hola' es: 'a' para N = 4\n",
            "La palabra predicha después de 'por' es: 'que' para N = 4\n",
            "La palabra predicha después de 'hoy' es: 'no' para N = 4\n",
            "La palabra predicha después de 'también' es: 'de' para N = 4\n",
            "La palabra predicha después de 'quien' es: 'no' para N = 4\n",
            "La palabra predicha después de 'puedo' es: 'de' para N = 4\n",
            "La palabra predicha después de 'yo' es: 'que' para N = 4\n",
            "La palabra predicha después de 'no' es: 'se' para N = 4\n",
            "La palabra predicha después de 'yo no' es: 'es' para N = 4\n",
            "La palabra predicha después de 'quien no' es: 'se' para N = 4\n",
            "La palabra predicha después de 'a que' es: 'la' para N = 4\n",
            "La palabra predicha después de 'el martes' es: 'de' para N = 4\n",
            "La palabra predicha después de 'que sale' es: 'no' para N = 4\n",
            "La palabra predicha después de 'a que hora' es: 'la' para N = 4\n",
            "La palabra predicha después de 'por las dudas' es: 'que' para N = 4\n",
            "La palabra predicha después de 'no se si el' es: 'es' para N = 4\n",
            "La palabra predicha después de 'yo no creo que' es: 'es' para N = 4\n"
          ]
        }
      ],
      "source": [
        "evaluar_lista([1,2,3,4],lista_predict,data_evaluar_lista)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-OtAKnqllVx"
      },
      "source": [
        "| Contexto            | N = 1 | N = 2 | N = 3 | N = 4 |\n",
        "|---------------------|-------|-------|-------|-------|\n",
        "| (vacio)             | que   | que   | que   | que   |\n",
        "| hola                | a     | a     | a     | a     |\n",
        "| por                 | que   | que   | que   | que   |\n",
        "| hoy                 | no    | no    | no    | no    |\n",
        "| también             | de    | de    | de    | de    |\n",
        "| quien               | no    | no    | no    | no    |\n",
        "| puedo               | de    | de    | de    | de    |\n",
        "| yo                  | que   | que   | que   | que   |\n",
        "| no                  | se    | se    | se    | se    |\n",
        "| yo no               | se    | es    | es    | es    |\n",
        "| quien no            | se    | se    | se    | se    |\n",
        "| a que               | no    | la    | la    | la    |\n",
        "| el martes           | y     | de    | de    | de    |\n",
        "| que sale            | el    | no    | no    | no    |\n",
        "| a que hora          | que   | no    | la    | la    |\n",
        "| por las dudas       | que   | de    | que   | que   |\n",
        "| no se si el         | de    | de    | que   | es    |\n",
        "| yo no creo que      | no    | que   | se    | es    |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3Pk_iFbqRh0"
      },
      "source": [
        "Como podemos observar en la tabla anterior, cuando el valor de\"N\" supera el largo de la frase, la predicción no cambia debido al diseño del algoritmo, donde consideramos las últimas N palabras, o la frase total si la misma no llega a \"N\". Dada la frase vacía: \"\", vemos que el inicio más frecuente consta de la palabra \"que\", indicando que la misma es muy frecuente en el conjunto de mensajes. Esto tiene sentido, ya que \"que\", luego del preprocesamiento puede abarcar varias categorías gramaticales como lo son: pronombre relativo,conjunción subordinante, pronombre interrogativo, conjunción causal, conjunción consecutiva, entre otras.\n",
        "\n",
        "Continuando el análisis, para N = 1 consideramos que las predicciones son especialmente malas para las frases: \"a que hora\", \"no se si el\" y \"yo no creo que\", dado que la palabra predicha no se ajusta a ninguna frase coherente a nuestro parecer. En cambio, para las demás sí es mucho más fácil pensar una frase coherente que utilice la predicción dados dichos contextos. Por ejemplo, luego de \"el martes\", tiene sentido \"y\" ya que nos podríamos estar refiriendo a un grupo de días para determinada actividad. Por lo tanto, al considerar únicamente la palabra previa para predecir la siguiente, no se obtienen muy malos resultados si el contexto es poco, pero si este es mayor, es más difícil que la predicción resulte coherente.\n",
        "\n",
        "Para N=2, vemos que salvo dos frases de largo 2 o mayor, la predicción del algoritmo cambia aprovechando que se tiene un mayor contexto para dicha tarea. Para la frase \"quien no\", que se mantenga la predicción \"se\" es entendible debido a que su probabilidad previa debe ser mucho mayor a \"puede\" por ejemplo, la cual podría ser a nuestra consideración una mejor predicción.\n",
        "\n",
        "Para las frases \"que sale\" y \"yo no\", consideramos que las predicciones empeoran para N > 1. A su vez, para las dos frases de largo 4, creemos que la predicción es más adecuada para N = 3 que para N = 4, lo que podría ser un indicio de que al ir incorporando más contexto, de la productoria se irán obteniendo números cada vez más chicos, dónde las probabilidades previas tendrán un mayor impacto. Debido a esto, las stop-words pasarán a ser constantemente sugeridas.\n",
        "\n",
        "En cuanto al argumento anterior, pensamos que dicho enfoque no está del todo alejado de la realidad, donde los teclados suelen ofrecer 3 opciones al predecir, siendo muchas de estas stop-words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eF1Tl_E17ts"
      },
      "source": [
        "\\\n",
        "Ahora, analizaremos la segunda palabra más probable según Naive Bayes para N =2, 3, 4. Utilizaremos dichos valores para ver qué otras palabras se hubieran sugerido si no consideramos la de mayor probabilidad. Dicho escenario lo resumiremos en una tabla, donde mostraremos las log_probabilidades utilizadas en la implementación para facilitar la lectura y el análisis numérico. El código utilizado para recolectar los datos de las tablas es el siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPy0E8T_ZpS8"
      },
      "outputs": [],
      "source": [
        "predictor = NaiveBayesPredictor(3)\n",
        "data_top_3 = data.copy()\n",
        "predictor.train(data_top_3)\n",
        "predecir_palabras(lista_predict,predictor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsZ94yJHZpS7",
        "outputId": "4f9f6fd1-2272-4546-cb2c-cd707d44ffc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La palabra predicha después de '' es: 'que' para N = 1\n",
            "La palabra predicha después de 'hola' es: 'a' para N = 1\n",
            "La palabra predicha después de 'por' es: 'que' para N = 1\n",
            "La palabra predicha después de 'hoy' es: 'no' para N = 1\n",
            "La palabra predicha después de 'también' es: 'de' para N = 1\n",
            "La palabra predicha después de 'quien' es: 'no' para N = 1\n",
            "La palabra predicha después de 'puedo' es: 'de' para N = 1\n",
            "La palabra predicha después de 'yo' es: 'que' para N = 1\n",
            "La palabra predicha después de 'no' es: 'se' para N = 1\n",
            "La palabra predicha después de 'yo no' es: 'se' para N = 1\n",
            "La palabra predicha después de 'quien no' es: 'se' para N = 1\n",
            "La palabra predicha después de 'a que' es: 'no' para N = 1\n",
            "La palabra predicha después de 'el martes' es: 'y' para N = 1\n",
            "La palabra predicha después de 'que sale' es: 'el' para N = 1\n",
            "La palabra predicha después de 'a que hora' es: 'que' para N = 1\n",
            "La palabra predicha después de 'por las dudas' es: 'que' para N = 1\n",
            "La palabra predicha después de 'no se si el' es: 'de' para N = 1\n",
            "La palabra predicha después de 'yo no creo que' es: 'no' para N = 1\n",
            "La palabra predicha después de '' es: 'que' para N = 2\n",
            "La palabra predicha después de 'hola' es: 'a' para N = 2\n",
            "La palabra predicha después de 'por' es: 'que' para N = 2\n",
            "La palabra predicha después de 'hoy' es: 'no' para N = 2\n",
            "La palabra predicha después de 'también' es: 'de' para N = 2\n",
            "La palabra predicha después de 'quien' es: 'no' para N = 2\n",
            "La palabra predicha después de 'puedo' es: 'de' para N = 2\n",
            "La palabra predicha después de 'yo' es: 'que' para N = 2\n",
            "La palabra predicha después de 'no' es: 'se' para N = 2\n",
            "La palabra predicha después de 'yo no' es: 'es' para N = 2\n",
            "La palabra predicha después de 'quien no' es: 'se' para N = 2\n",
            "La palabra predicha después de 'a que' es: 'la' para N = 2\n",
            "La palabra predicha después de 'el martes' es: 'de' para N = 2\n",
            "La palabra predicha después de 'que sale' es: 'no' para N = 2\n",
            "La palabra predicha después de 'a que hora' es: 'no' para N = 2\n",
            "La palabra predicha después de 'por las dudas' es: 'de' para N = 2\n",
            "La palabra predicha después de 'no se si el' es: 'de' para N = 2\n",
            "La palabra predicha después de 'yo no creo que' es: 'que' para N = 2\n",
            "La palabra predicha después de '' es: 'que' para N = 3\n",
            "La palabra predicha después de 'hola' es: 'a' para N = 3\n",
            "La palabra predicha después de 'por' es: 'que' para N = 3\n",
            "La palabra predicha después de 'hoy' es: 'no' para N = 3\n",
            "La palabra predicha después de 'también' es: 'de' para N = 3\n",
            "La palabra predicha después de 'quien' es: 'no' para N = 3\n",
            "La palabra predicha después de 'puedo' es: 'de' para N = 3\n",
            "La palabra predicha después de 'yo' es: 'que' para N = 3\n",
            "La palabra predicha después de 'no' es: 'se' para N = 3\n",
            "La palabra predicha después de 'yo no' es: 'es' para N = 3\n",
            "La palabra predicha después de 'quien no' es: 'se' para N = 3\n",
            "La palabra predicha después de 'a que' es: 'la' para N = 3\n",
            "La palabra predicha después de 'el martes' es: 'de' para N = 3\n",
            "La palabra predicha después de 'que sale' es: 'no' para N = 3\n",
            "La palabra predicha después de 'a que hora' es: 'la' para N = 3\n",
            "La palabra predicha después de 'por las dudas' es: 'que' para N = 3\n",
            "La palabra predicha después de 'no se si el' es: 'que' para N = 3\n",
            "La palabra predicha después de 'yo no creo que' es: 'se' para N = 3\n",
            "La palabra predicha después de '' es: 'que' para N = 4\n",
            "La palabra predicha después de 'hola' es: 'a' para N = 4\n",
            "La palabra predicha después de 'por' es: 'que' para N = 4\n",
            "La palabra predicha después de 'hoy' es: 'no' para N = 4\n",
            "La palabra predicha después de 'también' es: 'de' para N = 4\n",
            "La palabra predicha después de 'quien' es: 'no' para N = 4\n",
            "La palabra predicha después de 'puedo' es: 'de' para N = 4\n",
            "La palabra predicha después de 'yo' es: 'que' para N = 4\n",
            "La palabra predicha después de 'no' es: 'se' para N = 4\n",
            "La palabra predicha después de 'yo no' es: 'es' para N = 4\n",
            "La palabra predicha después de 'quien no' es: 'se' para N = 4\n",
            "La palabra predicha después de 'a que' es: 'la' para N = 4\n",
            "La palabra predicha después de 'el martes' es: 'de' para N = 4\n",
            "La palabra predicha después de 'que sale' es: 'no' para N = 4\n",
            "La palabra predicha después de 'a que hora' es: 'la' para N = 4\n",
            "La palabra predicha después de 'por las dudas' es: 'que' para N = 4\n",
            "La palabra predicha después de 'no se si el' es: 'es' para N = 4\n",
            "La palabra predicha después de 'yo no creo que' es: 'es' para N = 4\n"
          ]
        }
      ],
      "source": [
        "evaluar_lista([1,2,3,4],lista_predict,data_evaluar_lista)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mvsaLXLMM11"
      },
      "source": [
        "| Contexto para NB             | Top 1 (N=2)         | Top 2 (N=2)        | Top 1 (N=3)        | Top 2 (N=3)        | Top 1 (N=4)        | Top 2 (N=4)        |\n",
        "|-----------------------|---------------------|--------------------|--------------------|--------------------|--------------------|--------------------|\n",
        "|                       | que (-2.95)         | de (-3.32)         | que (-2.95)        | de (-3.32)         | que (-2.95)        | de (-3.32)         |\n",
        "| hola                  | a (-9.92)           | de (-10.29)        | a (-9.92)          | de (-10.29)        | a (-9.92)          | de (-10.29)        |\n",
        "| por                   | que (-8.28)         | el (-8.85)         | que (-8.28)        | el (-8.85)         | que (-8.28)        | el (-8.85)         |\n",
        "| hoy                   | no (-10.17)         | de (-10.29)        | no (-10.17)        | de (-10.29)        | no (-10.17)        | de (-10.29)        |\n",
        "| también               | de (-10.29)         | no (-10.58)        | de (-10.29)        | no (-10.58)        | de (-10.29)        | no (-10.58)        |\n",
        "| quien                 | no (-10.57)         | que (-10.6)        | no (-10.57)        | que (-10.6)        | no (-10.57)        | que (-10.6)        |\n",
        "| puedo                 | de (-10.28)         | que (-10.6)        | de (-10.28)        | que (-10.6)        | de (-10.28)        | que (-10.6)        |\n",
        "| yo                    | que (-8.86)         | no (-9.24)         | que (-8.86)        | no (-9.24)         | que (-8.86)        | no (-9.24)         |\n",
        "| no                    | se (-8.31)          | es (-8.46)         | se (-8.31)         | es (-8.46)         | se (-8.31)         | es (-8.46)         |\n",
        "| yo no                 | es (-14.77)         | lo (-15.21)        | es (-14.77)        | lo (-15.21)        | es (-14.77)        | lo (-15.21)        |\n",
        "| quien no              | se (-15.28)         | es (-16.11)        | se (-15.28)        | es (-16.11)        | se (-15.28)        | es (-16.11)        |\n",
        "| a que                 | la (-13.24)         | los (-13.5)        | la (-13.24)        | los (-13.5)        | la (-13.24)        | los (-13.5)        |\n",
        "| el martes             | de (-15.88)         | que (-15.89)       | de (-15.88)        | que (-15.89)       | de (-15.88)        | que (-15.89)       |\n",
        "| que sale              | no (-14.95)         | el (-15.38)        | no (-14.95)        | el (-15.38)        | no (-14.95)        | el (-15.38)        |\n",
        "| a que hora            | la (-20.9)          | los (-21.16)       | no (-14.26)        | es (-15.03)        | la (-20.9)         | los (-21.16)       |\n",
        "| por las dudas         | que (-21.74)        | el (-23.15)        | de (-15.72)        | que (-16.4)        | que (-21.74)       | el (-23.15)        |\n",
        "| no se si el           | que (-21.01)        | de (-21.58)        | de (-14.92)        | no (-15.12)        | es (-27.69)        | que (-28.18)       |\n",
        "| yo no creo que        | se (-19.93)         | es (-20.6)         | que (-14.49)       | no (-14.97)        | es (-26.92)        | que (-27.57)       |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwG9T_ge4SYe"
      },
      "source": [
        "Analizando la tabla, podemos notar que palabras ya mencionadas como \"que\" y otras stop-words resultan candidatas en varios ejemplos. Salvo para las frases: \"yo\", \"yo no\" y \"que sale\", donde consideramos que las palabras que obtuvieron la segunda mejor probabilidad son más convenientes, por lo menos para nuestra situación. El resto presenta predicciones adecuadas, donde se puede pensar fácilmente un contexto coherente como ya hemos ejemplificado. Como ya fue expuesto, para los N considerados era esperado no ver modificaciones al variar N en las primeras 14 filas, para frases de largo 2. Para mayor largo, las probabilidades comienzan a diferir debido a que la productoria, es decir la suma de logaritmos, agrega nuevos factores. Para las dos últimas frases, vemos como las dos palabras sugeridas cambian totalmente al pasar de N = 2 a N =3, siendo mejores los resultados para N = 2 en la última frase, ya que en el caso de 3, sugerir \"que\" luego de \"que\" es, generalmente, absurdo. De igual modo, la sugerencia para N = 4 no es preferible en dicha frase antes que la sugerencia para N =2 como ya mencionamos.\n",
        "\n",
        "\\\n",
        "Por otro lado, nos resulta llamativo el hecho de que para frases de largo 3, las probabilidades fueran las mismas para N = 2 y para N = 4, a pesar de que para N = 3 hubiera cambios en las palabras. Esto lo vemos como una recuperación del algoritmo ya que bajo nuestro punto de vista para N = 2, 4 la sugerencia es mejor. Algo similar pasa con la frase \"que sale\", donde para estos N no se sugiere \"el\" que hubiera sido a nuestro parecer mejor sugerencia que \"no\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUm5S9KYQPRi"
      },
      "source": [
        "### 4.1.2 Implementación bayesiana con TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8ZzmOIwQ7Jz"
      },
      "outputs": [],
      "source": [
        "predictor = NaiveBayesPredictor_TFIDF(3)\n",
        "data_test = data.copy()\n",
        "predictor.train(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjwo5Zrm3f_t"
      },
      "outputs": [],
      "source": [
        "data_evaluar_lista = data.copy()\n",
        "lista_predict = [\"\",\"hola\",\"por\",\"hoy\",\"también\",\"quien\",\"puedo\",\"yo\",\"no\",\"yo no\",\"quien no\",\"a que\",\"el martes\",\"que sale\",\"a que hora\",\"por las dudas\",\"no se si el\",\"yo no creo que\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JERoKIEs3iI9"
      },
      "outputs": [],
      "source": [
        "evaluar_lista([1,2,3,4],lista_predict,data_evaluar_lista,\"tf_idf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAMfgERb6SJf"
      },
      "source": [
        "| Contexto  |  N = 1 |  N = 2 |  N = 3 | N = 4 |\n",
        "|------------------|------------|------------|------------|------------|\n",
        "| ''               | 'que'      | 'que'      | 'que'      | 'que'      |\n",
        "| 'hola'           | 'de'       | 'de'       | 'de'       | 'de'       |\n",
        "| 'por'            | 'que'      | 'que'      | 'que'      | 'que'      |\n",
        "| 'hoy'            | 'la'       | 'la'       | 'la'       | 'la'       |\n",
        "| 'también'        | 'de'       | 'de'       | 'de'       | 'de'       |\n",
        "| 'quien'          | 'no'       | 'no'       | 'no'       | 'no'       |\n",
        "| 'puedo'          | 'de'       | 'de'       | 'de'       | 'de'       |\n",
        "| 'yo'             | 'de'       | 'de'       | 'de'       | 'de'       |\n",
        "| 'no'             | 'no'       | 'no'       | 'no'       | 'no'       |\n",
        "| 'yo no'          | 'no'       | 'que'      | 'que'      | 'que'      |\n",
        "| 'quien no'       | 'no'       | 'no'       | 'no'       | 'no'       |\n",
        "| 'a que'          | 'que'      | 'que'      | 'que'      | 'que'      |\n",
        "| 'el martes'      | 'los'      | 'los'      | 'los'      | 'los'      |\n",
        "| 'que sale'       | 'de'       | 'de'       | 'de'       | 'de'       |\n",
        "| 'a que hora'     | 'que'      | 'que'      | 'que'      | 'que'      |\n",
        "| 'por las dudas'  | 'te'       | 'te'       | 'que'      | 'que'      |\n",
        "| 'no se si el'    | 'que'      | 'que'      | 'que'      | 'que'      |\n",
        "| 'yo no creo que' | 'que'      | 'que'      | 'que'      | 'que'      |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wCBdQxl7bn-"
      },
      "source": [
        "##### Corpus Formal1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2hNXFYi7M2m"
      },
      "outputs": [],
      "source": [
        "predictor = NaiveBayesPredictor_TFIDF(3)\n",
        "data_top_3 = data.copy()\n",
        "predictor.train(data_top_3)\n",
        "\n",
        "predictor2 = NaiveBayesPredictor(3)\n",
        "data_top_3 = data.copy()\n",
        "predictor2.train(data_top_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI86qnmAa6la"
      },
      "source": [
        "Comparamos ambos predictores de forma subjetiva y realizamos una interpretación de los datos obtenidos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIm0RI2z7jRA",
        "outputId": "085dd0d4-0ea1-4047-f3fe-9e3ecb6fe04b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La palabra predicha después de 'ciento' es: 'diez' dadas las probabilidades obtenidas: '[('diez', -7.36), ('cincuenta', -7.89), ('veintisiete', -9.46), ('veintiocho', -10.1), ('que', -25.7)]'\n",
            "La palabra predicha después de 'magia' es: 'que' dadas las probabilidades obtenidas: '[('que', -25.7), ('de', -26.13), ('no', -26.14), ('la', -26.23), ('se', -26.43)]'\n",
            "La palabra predicha después de 'ajedrez' es: 'que' dadas las probabilidades obtenidas: '[('que', -25.7), ('de', -26.13), ('no', -26.14), ('la', -26.23), ('se', -26.43)]'\n",
            "La palabra predicha después de 'nosotros estamos' es: 'no' dadas las probabilidades obtenidas: '[('no', -26.93), ('si', -27.47), ('es', -27.82), ('de', -27.83), ('en', -28.21)]'\n",
            "La palabra predicha después de 'estamos' es: 'de' dadas las probabilidades obtenidas: '[('de', -4.8), ('en', -5.19), ('buscando', -8.15), ('esperando', -8.47), ('armando', -8.7)]'\n"
          ]
        }
      ],
      "source": [
        "# Predictor TF_IDF\n",
        "predecir_palabras([\"ciento\"],predictor,5)\n",
        "predecir_palabras([\"magia\"],predictor,5)\n",
        "predecir_palabras([\"ajedrez\"],predictor,5)\n",
        "predecir_palabras([\"nosotros estamos\"],predictor,5)\n",
        "predecir_palabras([\"estamos\"],predictor,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eI11A7pZ8oM",
        "outputId": "b38c5bf1-836e-4893-e093-8d9ae6e5b499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La palabra predicha después de 'ciento' es: 'que' dadas las probabilidades obtenidas: '[('que', -10.6), ('de', -10.97), ('no', -11.27)]'\n",
            "La palabra predicha después de 'magia' es: 'que' dadas las probabilidades obtenidas: '[('que', -10.6), ('de', -10.97), ('no', -11.26)]'\n",
            "La palabra predicha después de 'ajedrez' es: 'que' dadas las probabilidades obtenidas: '[('que', -10.6), ('de', -10.97), ('no', -11.26)]'\n",
            "La palabra predicha después de 'nosotros estamos' es: 'en' dadas las probabilidades obtenidas: '[('en', -17.48), ('de', -17.55), ('no', -17.85)]'\n",
            "La palabra predicha después de 'estamos' es: 'en' dadas las probabilidades obtenidas: '[('en', -9.81), ('de', -9.88), ('que', -10.61)]'\n"
          ]
        }
      ],
      "source": [
        "# Predictor de conteo\n",
        "predecir_palabras([\"ciento\"],predictor2,5)\n",
        "predecir_palabras([\"magia\"],predictor2,5)\n",
        "predecir_palabras([\"ajedrez\"],predictor2,5)\n",
        "predecir_palabras([\"nosotros estamos\"],predictor2,5)\n",
        "predecir_palabras([\"estamos\"],predictor2,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8kzD7aWawPM"
      },
      "source": [
        "Se puede observar como el predictor TF-IDF asigna probabilidades más altas a palabras menos frecuentes. como \"diez\" luego de ciento, o \"buscando\" luego de \"estamos\", mientras que el predictor basado en conteo sólo predice palabras como \"que\", \"de\" y \"no\", las cuales son de las palabras con más frecuencia en el lenguaje.\n",
        "\n",
        "Este resultado es el esperado, ya que la puntuación TF-IDF se basa en la frecuencia relativa de una palabra en un documento en comparación con su frecuencia en el conjunto de documentos. Por lo tanto, las palabras menos frecuentes en el lenguaje tendrán puntuaciones TF-IDF más altas en un contexto específico, como \"diez\" después de \"ciento\" o \"buscando\" después de \"estamos\", porque son palabras que son raras en ese contexto particular pero que tienen una relevancia significativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2SHysEh7Wbe"
      },
      "source": [
        "#### Corpus Informal1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u0ERP6W7gTG"
      },
      "outputs": [],
      "source": [
        "predictor = NaiveBayesPredictor_TFIDF(3)\n",
        "data_top_3 = data.copy()\n",
        "predictor.train(data_top_3)\n",
        "\n",
        "predictor2 = NaiveBayesPredictor(3)\n",
        "data_top_3 = data.copy()\n",
        "predictor2.train(data_top_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WmHNmJuQM_o",
        "outputId": "36794d17-f668-4852-cf58-5a1221e3d550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La palabra predicha después de 'yo' es: 'la' dadas las probabilidades obtenidas: '[('la', -5.16), ('que', -5.51), ('el', -5.53), ('se', -5.55), ('de', -5.59)]'\n",
            "La palabra predicha después de 'yo ya' es: 'de' dadas las probabilidades obtenidas: '[('de', -6.33), ('ya', -6.34), ('la', -6.54), ('se', -6.6), ('estoy', -6.78)]'\n",
            "La palabra predicha después de 'yo ya estoy' es: 'de' dadas las probabilidades obtenidas: '[('de', -7.52), ('se', -7.8), ('los', -8.25), ('no', -8.32), ('con', -8.52)]'\n",
            "La palabra predicha después de 'yo ya estoy en' es: 'de' dadas las probabilidades obtenidas: '[('de', -7.71), ('las', -8.16), ('los', -8.25), ('en', -8.28), ('se', -8.65)]'\n",
            "La palabra predicha después de 'yo ya estoy en un' es: 'para' dadas las probabilidades obtenidas: '[('para', -7.33), ('re', -7.74), ('de', -8.0), ('en', -8.03), ('como', -8.07)]'\n",
            "La palabra predicha después de 'yo ya estoy en un ciento' es: 'tres' dadas las probabilidades obtenidas: '[('tres', -8.64), ('cuatro', -9.06), ('uno', -9.13), ('doce', -9.27), ('cinco', -10.36)]'\n",
            "La palabra predicha después de 'yo ya estoy en un ciento tres por llegar' es: 'ahí' dadas las probabilidades obtenidas: '[('ahí', -9.3), ('al', -11.11), ('me', -29.32), ('que', -29.62), ('se', -29.85)]'\n"
          ]
        }
      ],
      "source": [
        "predecir_palabras([\"yo\",\"yo ya\",\"yo ya estoy\",\"yo ya estoy en\",\"yo ya estoy en un\",\"yo ya estoy en un ciento\",\"yo ya estoy en un ciento tres por llegar\"],predictor,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2oWySfNUGbw",
        "outputId": "674cd872-e8e8-4446-a8a9-ff17bad71710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La palabra predicha después de 'ciento' es: 'tres' dadas las probabilidades obtenidas: '[('tres', -7.23), ('uno', -7.4), ('cuatro', -7.8), ('doce', -8.02), ('cinco', -8.07)]'\n",
            "La palabra predicha después de 'magia' es: 'es' dadas las probabilidades obtenidas: '[('es', -6.79), ('negra', -11.04), ('que', -26.84), ('la', -26.86), ('de', -26.92)]'\n",
            "La palabra predicha después de 'ajedrez' es: 'de' dadas las probabilidades obtenidas: '[('de', -5.32), ('no', -5.73), ('sin', -7.97), ('gigante', -11.56), ('nombra', -12.3)]'\n",
            "La palabra predicha después de 'nosotros estamos' es: 'para' dadas las probabilidades obtenidas: '[('para', -7.32), ('en', -7.69), ('acá', -9.31), ('que', -28.4), ('de', -28.49)]'\n",
            "La palabra predicha después de 'estamos' es: 'de' dadas las probabilidades obtenidas: '[('de', -5.46), ('con', -6.0), ('en', -6.38), ('para', -6.42), ('por', -6.98)]'\n",
            "La palabra predicha después de 'mejor' es: 'que' dadas las probabilidades obtenidas: '[('que', -4.81), ('el', -4.98), ('la', -5.31), ('de', -5.55), ('un', -5.64)]'\n"
          ]
        }
      ],
      "source": [
        "predecir_palabras([\"ciento\"],predictor,5)\n",
        "predecir_palabras([\"magia\"],predictor,5)\n",
        "predecir_palabras([\"ajedrez\"],predictor,5)\n",
        "predecir_palabras([\"nosotros estamos\"],predictor,5)\n",
        "predecir_palabras([\"estamos\"],predictor,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UI7AqcjeueE"
      },
      "source": [
        "Observamos que se muestran palabras mucho menos frecuentes que las que esperaríamos con nuestra implementación por conteo, dando lugar a otras sugerencias. Como ya mencionaremos, todo depende del uso que se le de a la implementación del algoritmo. Considerando la implementación de un predictor de palabras como podría ser el teclado de un celular, observamos que es algo normal y que se corresponde con lo más probable el hecho de predecir stop-words. Realizamos la misma predicción a continuación con el predictor Naive Bayes por conteo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhSXT7syiR9F",
        "outputId": "413bf2f7-3f33-4bcf-c3fa-d6414515b50a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La palabra predicha después de 'ciento' es: 'cuarenta' dadas las probabilidades obtenidas: '[('cuarenta', -11.13), ('cincuenta', -11.2), ('sesenta', -11.25)]'\n",
            "La palabra predicha después de 'magia' es: 'es' dadas las probabilidades obtenidas: '[('es', -12.57), ('de', -12.62), ('que', -12.65)]'\n",
            "La palabra predicha después de 'ajedrez' es: 'de' dadas las probabilidades obtenidas: '[('de', -11.52), ('y', -12.02), ('no', -12.29)]'\n",
            "La palabra predicha después de 'nosotros estamos' es: 'en' dadas las probabilidades obtenidas: '[('en', -17.98), ('y', -20.07), ('no', -20.53)]'\n",
            "La palabra predicha después de 'estamos' es: 'en' dadas las probabilidades obtenidas: '[('en', -10.45), ('de', -11.93), ('con', -12.21)]'\n"
          ]
        }
      ],
      "source": [
        "predecir_palabras([\"ciento\"],predictor2,5)\n",
        "predecir_palabras([\"magia\"],predictor2,5)\n",
        "predecir_palabras([\"ajedrez\"],predictor2,5)\n",
        "predecir_palabras([\"nosotros estamos\"],predictor2,5)\n",
        "predecir_palabras([\"estamos\"],predictor2,5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPGh72kAjdi9"
      },
      "source": [
        "Observando las salidas se confirma nuestra afirmación anterior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlN2nLWv65P4"
      },
      "source": [
        "## 4.2 Medimos Precisión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPyKpnFs7BDD"
      },
      "source": [
        "A modo de experimentación, por más que sabemos que las métricas usuales en el curso para medir desempeño no son las adecuadas en este contexto, mediante la función \"evaluar_predictor()\" queremos ver cómo se comporta el algoritmo si utilizamos un 80% del Chat para entrenar el modelo, y al restante 20% de los mensajes le quitamos la última palabra para ver si el algoritmo es capaz de predecirla correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hoakl_4Rqrr"
      },
      "source": [
        "### 4.2.1 Implementación bayesiana por conteo de palabras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwQEP1ypTs8C"
      },
      "source": [
        "Chat 1 - 2000 mensajes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVa0T7zVoNeu",
        "outputId": "2cdb7c46-cf7a-4055-dc9d-389279bd4ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se obtuvo una precisión de:  0.03021978021978022\n"
          ]
        }
      ],
      "source": [
        "data_precision = data.copy()\n",
        "precision = evaluar_predictor(0.8, data_precision, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nmd9VW4PTt97"
      },
      "source": [
        "Chat2 - 30000 mensajes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_Xmv2dTTm35",
        "outputId": "9c81ddba-b20d-4280-b725-e5eff8d4ccc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se obtuvo una precisión de:  0.02664266426642664\n"
          ]
        }
      ],
      "source": [
        "data_precision = data.copy()\n",
        "precision = evaluar_predictor(0.8, data_precision, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B77pBrfFRvaB"
      },
      "source": [
        "### 4.2.2 Implementación bayesiana por TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE-9Z1Z0Tqtb"
      },
      "source": [
        "Chat 1 - 2000 mensajes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgUWA4pg5Xg-",
        "outputId": "9991b340-1d82-4917-e8d7-107d65f21182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se obtuvo una precisión de:  0.03296703296703297\n"
          ]
        }
      ],
      "source": [
        "data_precision = data.copy()\n",
        "precision = evaluar_predictor(0.8, data_precision, 3,\"tf_idf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ6KU5avTspT"
      },
      "source": [
        "Chat2 - 30000 mensajes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqwAKFkjTwTb",
        "outputId": "ddaf420e-d7f6-46a5-fc55-5963b3c6be9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se obtuvo una precisión de:  0.01782178217821782\n"
          ]
        }
      ],
      "source": [
        "data_precision = data.copy()\n",
        "precision = evaluar_predictor(0.8, data_precision, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC536pOnTzWa"
      },
      "source": [
        "### 4.2.3 Precisión - Observaciones:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F7jbP2L8Dhr"
      },
      "source": [
        "Como podemos ver en la salida, la precisión es muy mala, aproximadamente de un 3% para los casos más optimos (los cuales se dan en el corpus de menor tamaño), confirmando que evaluar el desempeño del algoritmo mediante este método no es adecuado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m0v26PDGeyd"
      },
      "source": [
        "## 4.3 Experimentación en vivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt5ppuF7b-vb"
      },
      "source": [
        "#### 4.3.1 Implementación por conteo de palabras:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUyq2lfqfT0w"
      },
      "source": [
        "Para cumplir con el requisito de reentrenar el modelo al finalizar cada frase, es decir, cada vez que se ingresa un PUNTO, se modifica el código que nos brindaron agregando dicha funcionalidad. A continuación, creamos una instancia del modelo para utilizar. Si se quiere utilizar otro valor de N, se debe cambiar en la celda siguiente al valor deseado. Nosotros utilizaremos N = 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2eXh73wHgiM"
      },
      "outputs": [],
      "source": [
        "# Renombramos predictor para eliminar conflictos en caso de que el orden de ejecucion no siga el flujo del Notebook.\n",
        "predictor_cliente = NaiveBayesPredictor(3)\n",
        "data_cliente = data.copy()\n",
        "predictor_cliente.train(data_cliente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbC4NyF7_tyO",
        "outputId": "33be3b0b-460e-4e6f-cbcd-ac8a75d4bc1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingrese la frase dando ENTER luego de \u001b[3mcada palabra\u001b[0m.\n",
            "Ingrese sólo ENTER para aceptar la recomendación sugerida, o escriba la siguiente palabra y de ENTER\n",
            "Ingrese '.' para comenzar con una frase nueva.\n",
            "Ingrese '..' para terminar el proceso.\n",
            ">> hola\n",
            "hola \u001b[3ma\u001b[0m\n",
            ">> \n",
            "hola a \u001b[3mlos\u001b[0m\n",
            ">> \n",
            "hola a los \u001b[3mque\u001b[0m\n",
            ">> \n",
            "hola a los que \u001b[3mlos\u001b[0m\n",
            ">> \n",
            "hola a los que los \u001b[3mno\u001b[0m\n",
            ">> \n",
            "hola a los que los no \u001b[3mse\u001b[0m\n",
            ">> \n",
            "hola a los que los no se \u001b[3mque\u001b[0m\n",
            ">> \n",
            "hola a los que los no se que \u001b[3mse\u001b[0m\n",
            ">> \n",
            "hola a los que los no se que se \u001b[3msi\u001b[0m\n",
            ">> \n",
            "hola a los que los no se que se si \u001b[3mno\u001b[0m\n",
            ">> \n",
            "hola a los que los no se que se si no \u001b[3mes\u001b[0m\n",
            ">> \n",
            "hola a los que los no se que se si no es \u001b[3mla\u001b[0m\n",
            ">> \n",
            "hola a los que los no se que se si no es la \u001b[3mque\u001b[0m\n",
            ">> \n",
            "hola a los que los no se que se si no es la que \u001b[3mque\u001b[0m\n",
            ">> \n",
            "hola a los que los no se que se si no es la que que \u001b[3mno\u001b[0m\n",
            ">> \n",
            "hola a los que los no se que se si no es la que que no \u001b[3mse\u001b[0m\n",
            ">> \n",
            "hola a los que los no se que se si no es la que que no se \u001b[3mse\u001b[0m\n",
            ">> ..\n"
          ]
        }
      ],
      "source": [
        "def recomendacion_bayesiana(frase):\n",
        "  sugerencia = predictor_cliente.predict(frase)\n",
        "  # Como dejamos que el algoritmo retorne las 3 palabras mas probables para el analisis del desempeño,\n",
        "  # ahora debemos simplemente retornar la mas probable\n",
        "  siguiente_palabra = sugerencia[0][0]\n",
        "  return siguiente_palabra\n",
        "\n",
        "##### LOOP PRINCIPAL #####\n",
        "print(\"Ingrese la frase dando ENTER luego de \\x1b[3mcada palabra\\x1b[0m.\")\n",
        "print(\"Ingrese sólo ENTER para aceptar la recomendación sugerida, o escriba la siguiente palabra y de ENTER\")\n",
        "print(\"Ingrese '.' para comenzar con una frase nueva.\")\n",
        "print(\"Ingrese '..' para terminar el proceso.\")\n",
        "\n",
        "frase = []\n",
        "palabra_sugerida = \"\"\n",
        "while 1:\n",
        "    palabra = input(\">> \")\n",
        "\n",
        "    if palabra == \"..\":\n",
        "      break\n",
        "\n",
        "    elif palabra == \".\":\n",
        "      print(\"----- Comenzando frase nueva -----\")\n",
        "      frase_parcial = \" \".join(frase)\n",
        "      predictor_cliente.train(frase_parcial)       # Renombramos\n",
        "      frase = []\n",
        "      frase_parcial = \"\"\n",
        "\n",
        "    elif palabra == \"\": # acepta última palabra sugerida\n",
        "      frase.append(palabra_sugerida)\n",
        "\n",
        "    else: # escribió una palabra\n",
        "      frase.append(palabra)\n",
        "\n",
        "    if frase:\n",
        "      frase_parcial = \" \".join(frase)\n",
        "      palabra_sugerida = recomendacion_bayesiana(frase_parcial)\n",
        "\n",
        "      frase_propuesta = frase.copy()\n",
        "      frase_propuesta.append(\"\\x1b[3m\"+ palabra_sugerida +\"\\x1b[0m\")\n",
        "\n",
        "      print(\" \".join(frase_propuesta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW7_s2FgJiSM"
      },
      "source": [
        "Al aceptar constantemente la sugerencia que brinda Naive Bayes, las frases que se obtienen no son coherentes semánticamente. Como dijimos, esto se debe principalmente a la abundante cantidad de stop-words presentes en los mensajes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsx4PCCOcIWc"
      },
      "source": [
        "#### 4.3.2 Implementación TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pCVwE8CcOZj"
      },
      "outputs": [],
      "source": [
        "# Renombramos predictor para eliminar conflictos en caso de que el orden de ejecucion no siga el flujo del Notebook.\n",
        "predictor_cliente = NaiveBayesPredictor_TFIDF(3)\n",
        "data_cliente = data.copy()\n",
        "predictor_cliente.train(data_cliente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdeRsQ5acOZr",
        "outputId": "57343c8a-ff51-455d-9f6b-1427c96e854b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingrese la frase dando ENTER luego de \u001b[3mcada palabra\u001b[0m.\n",
            "Ingrese sólo ENTER para aceptar la recomendación sugerida, o escriba la siguiente palabra y de ENTER\n",
            "Ingrese '.' para comenzar con una frase nueva.\n",
            "Ingrese '..' para terminar el proceso.\n",
            ">> hay grupo de\n",
            "hay grupo de \u001b[3mque\u001b[0m\n",
            ">> \n",
            "hay grupo de que \u001b[3mde\u001b[0m\n",
            ">> \n",
            "hay grupo de que de \u001b[3mde\u001b[0m\n",
            ">> \n",
            "hay grupo de que de de \u001b[3mde\u001b[0m\n",
            ">> \n",
            "hay grupo de que de de de \u001b[3mbien\u001b[0m\n",
            ">> \n",
            "hay grupo de que de de de bien \u001b[3mel\u001b[0m\n",
            ">> \n",
            "hay grupo de que de de de bien el \u001b[3mde\u001b[0m\n",
            ">> \n",
            "hay grupo de que de de de bien el de \u001b[3mde\u001b[0m\n",
            ">> \n",
            "hay grupo de que de de de bien el de de \u001b[3mde\u001b[0m\n",
            ">> \n",
            "hay grupo de que de de de bien el de de de \u001b[3mbien\u001b[0m\n",
            ">> ..\n"
          ]
        }
      ],
      "source": [
        "def recomendacion_bayesiana_TFIDF(frase):\n",
        "  sugerencia = predictor_cliente.predict(frase)\n",
        "  # Como dejamos que el algoritmo retorne las 3 palabras mas probables para el analisis del desempeño,\n",
        "  # ahora debemos simplemente retornar la mas probable\n",
        "  siguiente_palabra = sugerencia[0][0]\n",
        "  return siguiente_palabra\n",
        "\n",
        "##### LOOP PRINCIPAL #####\n",
        "print(\"Ingrese la frase dando ENTER luego de \\x1b[3mcada palabra\\x1b[0m.\")\n",
        "print(\"Ingrese sólo ENTER para aceptar la recomendación sugerida, o escriba la siguiente palabra y de ENTER\")\n",
        "print(\"Ingrese '.' para comenzar con una frase nueva.\")\n",
        "print(\"Ingrese '..' para terminar el proceso.\")\n",
        "\n",
        "frase = []\n",
        "palabra_sugerida = \"\"\n",
        "while 1:\n",
        "    palabra = input(\">> \")\n",
        "\n",
        "    if palabra == \"..\":\n",
        "      break\n",
        "\n",
        "    elif palabra == \".\":\n",
        "      print(\"----- Comenzando frase nueva -----\")\n",
        "      frase_parcial = \" \".join(frase)\n",
        "      predictor_cliente.train(frase_parcial,3)       # Renombramos\n",
        "      frase = []\n",
        "      frase_parcial = \"\"\n",
        "\n",
        "    elif palabra == \"\": # acepta última palabra sugerida\n",
        "      frase.append(palabra_sugerida)\n",
        "\n",
        "    else: # escribió una palabra\n",
        "      frase.append(palabra)\n",
        "\n",
        "    if frase:\n",
        "      frase_parcial = \" \".join(frase)\n",
        "      palabra_sugerida = recomendacion_bayesiana_TFIDF(frase_parcial)\n",
        "\n",
        "      frase_propuesta = frase.copy()\n",
        "      frase_propuesta.append(\"\\x1b[3m\"+ palabra_sugerida +\"\\x1b[0m\")\n",
        "\n",
        "      print(\" \".join(frase_propuesta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdPRL9SuLPdm"
      },
      "source": [
        "# 5. Conclusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylx2eNQGLPdm"
      },
      "source": [
        "A continuacion presentaremos una breve conclusión del trabajo realizado.\n",
        "\n",
        "- En nuestra opinión, el N con el que se obtuvieron mejores resultados fue con el valor 3. Sin embargo, como ya fue comentada la dificultad que presentaba medir el desempeño de un algoritmo como este, dicha observación es subjetiva. Para el caso N = 1, consideramos que no se obtuvieron malas sugerencias para frases de largo pequeño. Sin embargo, al aumentar dicha longitud, los valores de N mayores iban ofreciendo mejores sugerencias aprovechando la presencia de un mayor contexto. Por otro lado, como mencionamos anteriormente, para N = 4 notamos que la palabra sugerida era menos adecuada respecto a N = 3. A su vez, dado que en Whatsapp se encuentran muchos mensajes cortos N = 3 permite considerar suficiente contexto sin que este le perjudique, por ejemplo al sobreajustarse a palabras que pertenecían a otra oración anterior.\n",
        "\n",
        "- A su vez, como mencionamos anteriormente, observamos que muchas palabras predichas refieren a stop-words que hasta cierto punto es coherente ya que son frecuentemente utilizadas, pero por otro lado una frase hecha puramente de stop-words usualmente no tiene coherencia como pudimos observar en la experimentacion en vivo.\n",
        "\n",
        "- Observamos que la técnica tf-idf para medir la importancia de los términos puede representar una posible mejora en el caso de querer disminuir la cantidad de stop-words predichas por esta implementación. Se verificó que al implementarlo, se disminuye la probabilidad de las stop-words sugeridas y se aumenta la probabilidad de las palabras con poca frecuencia dentro del corpus.\n",
        "\n",
        "- Consideramos que es esencial encontrar un equilibrio adecuado entre la frecuencia de las palabras y la coherencia en la generación de predicciones. En este sentido, sería útil considerar no solo la palabra en sí, sino también su categoría gramatical, como sustantivo, verbo o adjetivo. Esta consideración podría no solo enriquecer el proceso de predicción, sino que también evita depender excesivamente de palabras comunes o conectores, como las stop-words. En otras palabras, reconocemos el frecuente uso de las stop-words, pero introducir las reglas gramaticales podría ser el medio para limitar su uso con el fin de mantener la coherencia en las predicciones."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_wCBdQxl7bn-",
        "g2SHysEh7Wbe"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
